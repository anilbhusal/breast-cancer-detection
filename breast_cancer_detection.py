# -*- coding: utf-8 -*-
"""Breast Cancer Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iMJ2G-lA-NstA53bQIvonGUSXzRPNo5E

# Data Preprocessing

dataset link: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

## Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/data.csv')

dataset.head()

"""## Data Exploration"""

dataset.shape

dataset.info()

dataset.select_dtypes(include = 'object').columns

len(dataset.select_dtypes(include = 'object').columns)

dataset.select_dtypes(include = ['float64', 'int64']).columns

len(dataset.select_dtypes(include = ['float64', 'int64']).columns)

# Statistical Summary
dataset.describe()

dataset.columns

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

dataset.columns[dataset.isnull().any()]

len(dataset.columns[dataset.isnull().any()])

dataset['Unnamed: 32'].count()

dataset = dataset.drop(columns='Unnamed: 32')

dataset.shape

dataset.isnull().values.any()

"""## Dealing with categorical data"""

dataset.select_dtypes(include = 'object').columns

dataset['diagnosis'].unique()

dataset['diagnosis'].nunique()

# One Hot Encoding
dataset = pd.get_dummies(data = dataset, drop_first = True)

dataset.head()

"""## Countplot"""

sns.countplot(dataset['diagnosis_M'], label = 'count')
plt.show()

# B values
(dataset.diagnosis_M == 0).sum()

# M values
(dataset.diagnosis_M == 1).sum()

"""## Correlation matrix and heatmap"""

dataset_2 = dataset.drop(columns = 'diagnosis_M')

dataset_2.head()

dataset_2.corrwith(dataset['diagnosis_M']).plot.bar(
    figsize=(20,10), title = 'corrolated with diagnosis_M', rot=45, grid =True
)

# Correlation matrix
corr = dataset.corr()

corr

# heatmap
plt.figure(figsize =(20,10))
sns.heatmap(corr, annot= True)

"""## Splitting the dataset"""

dataset.head()

# matrix of features/ independent variables
x = dataset.iloc[:,1:-1].values

x.shape

#target variables/dependent variable
y= dataset.iloc[:,-1].values

y.shape

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state =0)

x_train.shape

x_test.shape

y_train.shape

y_test.shape

"""## Feature scaling"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test



"""# Building the model

## Logistic regression
"""

from sklearn.linear_model import LogisticRegression

classifier_lr = LogisticRegression(random_state =0)

classifier_lr.fit(x_train,y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
prec = precision_score(y_test,y_pred)
rec = recall_score(y_test, y_pred)

results = pd.DataFrame([['Logistic Regression',acc,f1,prec,rec]],columns=['Model','Accuracy','F1 Score','Precision', 'Recall'])

results

cm = confusion_matrix(y_test,y_pred)
print(cm)

"""### Cross validation"""

from sklearn.model_selection import cross_val_score

accuracy = cross_val_score(estimator= classifier_lr, X = x_train, y = y_train, cv=10)

print("Accuracy is {:.2f} %".format(accuracy.mean()*100))
print("Standard deviation is {:.2f} %".format(accuracy.std()*100))

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier

classifier_rm = RandomForestClassifier(random_state =0)
classifier_rm.fit(x_train, y_train)

y_pred = classifier_rm.predict(x_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
prec = precision_score(y_test,y_pred)
rec = recall_score(y_test, y_pred)

model_results = pd.DataFrame([['Random forest',acc,f1,prec,rec]],columns=['Model','Accuracy','F1 Score','Precision', 'Recall'])

results= results.append(model_results, ignore_index = True)

results

cm = confusion_matrix(y_test,y_pred)
print(cm)

"""### Cross Validation"""

from sklearn.model_selection import cross_val_score

accuracy = cross_val_score(estimator= classifier_rm, X = x_train, y = y_train, cv=10)

print("Accuracy is {:.2f} %".format(accuracy.mean()*100))
print("Standard deviation is {:.2f} %".format(accuracy.std()*100))

"""# Randomized Search to find the best parameters(Logistic Regression)"""

from sklearn.model_selection import RandomizedSearchCV

parameters = {
    'penalty' : ['l1','l2','elasticnet','none'],
    'C' : [0.25, 0.5, 0.75, 1.0 ,1.25, 1.5, 1.75, 2.0],
    'solver' : ['newton-cg','lbfgs','liblinear', 'sag', 'saga']
}

parameters

random_search = RandomizedSearchCV(estimator = classifier_lr, param_distributions =parameters, n_iter =10, scoring = 'roc_auc', n_jobs =-1, cv=10, verbose=3)

random_search.fit(x_train, y_train)

random_search.best_estimator_

random_search.best_score_

random_search.best_params_

"""# Final model(Logistic Regression)"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(C=0.75, random_state=0, solver='newton-cg', penalty = 'l2')
classifier.fit(x_train,y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
prec = precision_score(y_test,y_pred)
rec = recall_score(y_test, y_pred)

model_results = pd.DataFrame([['Final Logistic regression',acc,f1,prec,rec]],columns=['Model','Accuracy','F1 Score','Precision', 'Recall'])
results= results.append(model_results, ignore_index = True)
results

"""## Cross Validation"""

from sklearn.model_selection import cross_val_score
accuracy = cross_val_score(estimator= classifier, X = x_train, y = y_train, cv=10)
print("Accuracy is {:.2f} %".format(accuracy.mean()*100))
print("Standard deviation is {:.2f} %".format(accuracy.std()*100))

"""# Predicting a single observation"""

dataset.head()

single_obs=[[17.99,10.38,122.8,1001,0.11840,0.227,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.049,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]]

single_obs

classifier.predict(sc.transform(single_obs))